{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,GRU, Dropout\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "import yfinance as yf\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1. Data Acquisition:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download historical data for Nifty IT Index\n",
    "nifty_it = yf.download('^CNXIT', start='2010-01-01', end='2024-11-10', interval='1d')\n",
    "nifty_it = nifty_it[['Close']].fillna(method='ffill')\n",
    "\n",
    "nifty_it.tail()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nifty_it.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2. EDA and Feturing Engineering "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nifty_it.plot(figsize=(20,7))\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('IT nifty Price')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "visualizing the trends"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Apply seasonal decomposition on the data\n",
    "results = seasonal_decompose(nifty_it['Close'], model='additive', period=253)\n",
    "\n",
    "# Plot the original, trend, seasonal, and residual components\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Original time series\n",
    "plt.subplot(4, 1, 1)\n",
    "plt.plot(nifty_it['Close'], label='Original')\n",
    "plt.legend()\n",
    "plt.title('Original Time Series')\n",
    "\n",
    "# Trend component\n",
    "plt.subplot(4, 1, 2)\n",
    "plt.plot(results.trend, label='Trend')\n",
    "plt.legend()\n",
    "plt.title('Trend Component')\n",
    "\n",
    "# Seasonal component\n",
    "plt.subplot(4, 1, 3)\n",
    "plt.plot(results.seasonal, label='Seasonal')\n",
    "plt.legend()\n",
    "plt.title('Seasonal Component')\n",
    "\n",
    "# Residual component\n",
    "plt.subplot(4, 1, 4)\n",
    "plt.plot(results.resid, label='Residual')\n",
    "plt.legend()\n",
    "plt.title('Residual Component')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4. Train-Test Split and Scaling**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train-test split\n",
    "train_size = int(len(nifty_it) * 0.8)\n",
    "train, test = nifty_it.iloc[:train_size], nifty_it.iloc[train_size:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaling\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(nifty_it)\n",
    "scaled_train = scaler.transform(train)\n",
    "scaled_test = scaler.transform(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5. Data Preparation for LSTM**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape data for LSTM\n",
    "def create_sequences(data, n_input):\n",
    "    X, y = [], []\n",
    "    for i in range(len(data) - n_input):\n",
    "        X.append(data[i:i + n_input])\n",
    "        y.append(data[i + n_input])\n",
    "    return np.array(X), np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_input = 3\n",
    "X_train, y_train = create_sequences(scaled_train, n_input)\n",
    "X_test, y_test = create_sequences(scaled_test, n_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**6. Building the LSTM Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the LSTM model\n",
    "model = Sequential()\n",
    "model.add(GRU(64, return_sequences=True, input_shape=(n_input, 1)))\n",
    "model.add(Dropout(0.2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(GRU(units=64, return_sequences=True))\n",
    "model.add(Dropout(0.2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(GRU(units=64))\n",
    "model.add(Dropout(0.1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dense(1))\n",
    "model.compile(optimizer='adam', loss='mae')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**7. Training the Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "history = model.fit(X_train, y_train, epochs=20, batch_size=32, verbose=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**8. Plotting Training Loss**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract training loss from the history\n",
    "train_loss_history = history.history['loss']\n",
    "\n",
    "# Plot the training loss over epochs\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(train_loss_history, label='Training Loss', marker='o')\n",
    "plt.title('Training Loss Over Epochs')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 5. Model Evaluation : Making Predictions and Plotting Results**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictions\n",
    "train_predict = model.predict(X_train)\n",
    "test_predict = model.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model\n",
    "train_loss = model.evaluate(X_train, y_train, verbose=0)\n",
    "test_loss = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(f'Training MSE: {train_loss}')\n",
    "print(f'Testing MSE: {test_loss}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inverse transform predictions\n",
    "train_predict = scaler.inverse_transform(train_predict)\n",
    "y_train = scaler.inverse_transform(y_train.reshape(-1, 1))\n",
    "\n",
    "test_predict = scaler.inverse_transform(test_predict)\n",
    "y_test = scaler.inverse_transform(y_test.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate MAE, MSE, MAPE for training set\n",
    "train_mae = mean_absolute_error(y_train, train_predict)\n",
    "train_mape = np.mean(np.abs((y_train - train_predict) / y_train)) * 100\n",
    "\n",
    "train_mse = mean_squared_error(y_train, train_predict)\n",
    "\n",
    "print(f'Training MAE: {train_mae:.4f}')\n",
    "print(f'Training MAPE: {train_mape:.4f}%')\n",
    "print(f'Training MSE: {train_mse:.4f}')\n",
    "\n",
    "# Calculate MSE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate MAE, MSE, MAPE for testing set\n",
    "test_mae = mean_absolute_error(y_test, test_predict)\n",
    "test_mape = np.mean(np.abs((y_test - test_predict) / y_test)) * 100\n",
    "mse_test = mean_squared_error(y_test, test_predict)\n",
    "\n",
    "print(f'Testing MAE: {test_mae:.4f}')\n",
    "print(f'Testing MAPE: {test_mape:.4f}%')\n",
    "print(f'Testing MSE: {train_mse:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot predictions\n",
    "plt.figure(figsize=(16, 8))\n",
    "\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.plot(y_train, label='Actual Train')\n",
    "plt.plot(train_predict, label='Predicted Train')\n",
    "\n",
    "plt.title('Training Set')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 10))\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.plot(y_test, label='Actual Test')\n",
    "plt.plot(test_predict, label='Predicted Test')\n",
    "plt.title('GRU testing Set')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deeptrend",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
